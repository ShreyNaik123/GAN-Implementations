{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMn6U1E1ym8dHIhbP4QlaXS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShreyNaik123/GAN-Implementations/blob/main/Cyclegan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "prjgYCct8-qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(Layer):\n",
        "  def __init__(self,filters,stride):\n",
        "    super(Block,self).__init__()\n",
        "    self.conv = Sequential([\n",
        "        layers.Conv2D(filters=filters, kernel_size=4, strides=stride, padding='same'),\n",
        "        layers.GroupNormalization(groups=1), #when groups is set as the number of channels in the input image to the function it acts like InstanceNormalization\n",
        "        layers.LeakyReLU(0.2),\n",
        "    ])\n",
        "\n",
        "  def call(self,x):\n",
        "    return self.conv(x)"
      ],
      "metadata": {
        "id": "zxTC0Q1b_gYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(Model):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.initial = Sequential([\n",
        "        layers.Conv2D(filters=64,\n",
        "                      kernel_size=4,\n",
        "                      strides=2,\n",
        "                      padding='same'),\n",
        "        layers.LeakyReLU(0.2),\n",
        "    ])\n",
        "\n",
        "    self.block1 = Block(128,2)\n",
        "    self.block2 = Block(256,2)\n",
        "    self.block3 = Block(512,1)\n",
        "    self.final = Block(1,1)\n",
        "\n",
        "  def call(self,x):\n",
        "    x = self.initial(x)\n",
        "    x = self.block1(x)\n",
        "    x = self.block2(x)\n",
        "    x = self.block3(x)\n",
        "    return tf.keras.activations.sigmoid(self.final(x))"
      ],
      "metadata": {
        "id": "GliS-e17KI1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = tf.random.uniform((1,256,256,3))\n",
        "model = Discriminator()\n",
        "pred = model(test)\n",
        "print(pred.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ-AK1QWa0P8",
        "outputId": "33439114-1d47-49a3-e433-a5441b1d9a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 32, 32, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(Layer):\n",
        "  def __init__(self, filters, kernel_size=4,down=True, activation=True, stride=1, **kwargs):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    self.conv = Sequential()\n",
        "    if down:\n",
        "      self.conv.add(layers.Conv2D(filters=filters, kernel_size=kernel_size,padding='same',strides=stride))\n",
        "    else:\n",
        "      self.conv.add(layers.Conv2DTranspose(filters=filters,kernel_size=kernel_size, padding='same',strides=stride))\n",
        "    self.conv.add(layers.GroupNormalization(groups=1))\n",
        "    if activation:\n",
        "      self.conv.add(layers.ReLU())\n",
        "    else:\n",
        "      self.conv.add(layers.Identity())\n",
        "\n",
        "  def call(self, x):\n",
        "    return self.conv(x)"
      ],
      "metadata": {
        "id": "IfpxGQ-8bCuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(Layer):\n",
        "  def __init__(self, filters):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    self.block = Sequential([\n",
        "        ConvBlock(filters=filters, kernel_size=3),\n",
        "        ConvBlock(filters=filters, kernel_size=3, activation=False)\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    return x + self.block(x)"
      ],
      "metadata": {
        "id": "BshjBa1clOBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad(input_tensor, padding_size):\n",
        "  return tf.pad(input_tensor, [[0, 0], [padding_size, padding_size], [padding_size, padding_size], [0, 0]], mode='CONSTANT')"
      ],
      "metadata": {
        "id": "jzYw2c711rXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(Model):\n",
        "  def __init__(self, num_residual):\n",
        "    super(Generator, self).__init__()\n",
        "    self.initial = Sequential([\n",
        "        layers.Conv2D(64, kernel_size=7, strides=1, padding='same'),\n",
        "        layers.ReLU(),\n",
        "    ])\n",
        "\n",
        "    self.down = Sequential([\n",
        "        ConvBlock(128, kernel_size=3,stride=2,padding='same'),\n",
        "        ConvBlock(256, kernel_size=3, stride=2, padding='same')\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "    self.residual = Sequential()\n",
        "    for _  in range(num_residual):\n",
        "      self.residual.add(ResidualBlock(256))\n",
        "\n",
        "    self.up = Sequential([\n",
        "        ConvBlock(128, down=False, kernel_size=3, stride=2,padding='same', output_padding=1),\n",
        "        ConvBlock(64, down=False, kernel_size=3, stride=2, padding='same', output_padding=1),\n",
        "    ])\n",
        "\n",
        "    self.last = Sequential([\n",
        "        ConvBlock(3, kernel_size=7, stride=1)\n",
        "    ])\n",
        "\n",
        "\n",
        "  def call(self, x):\n",
        "    x = self.initial(x)\n",
        "    x = self.down(x)\n",
        "    x = self.residual(x)\n",
        "    x = self.up(x)\n",
        "    return tf.keras.activations.tanh(self.last(x))\n"
      ],
      "metadata": {
        "id": "UeSJTwt-nV_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = tf.random.uniform((1,256,256,3))\n",
        "model = Generator(9)\n",
        "pred = model(test)\n",
        "print(pred.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBReAb_wBHvp",
        "outputId": "177cb8a6-7a70-43d1-f6d1-f381a33e061c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 256, 256, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "l1 = tf.keras.losses.MeanAbsoluteError()\n",
        "disc_opt_z = tf.keras.optimizers.legacy.Adam(learning_rate=1e-5,beta_1=0.5,beta_2=0.999)\n",
        "disc_opt_h = tf.keras.optimizers.legacy.Adam(learning_rate=1e-5,beta_1=0.5,beta_2=0.999)\n",
        "gen_opt_z = tf.keras.optimizers.legacy.Adam(learning_rate=1e-5,beta_1=0.5,beta_2=0.999)\n",
        "gen_opt_h = tf.keras.optimizers.legacy.Adam(learning_rate=1e-5,beta_1=0.5,beta_2=0.999)"
      ],
      "metadata": {
        "id": "tWmyzsbyj6At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleGan(Model):\n",
        "  def __init__(self, disc_h, disc_z, gen_h, gen_z):\n",
        "    super(CycleGan, self).__init__()\n",
        "    self.disc_h = disc_h\n",
        "    self.disc_z = disc_z\n",
        "    self.gen_h = gen_h\n",
        "    self.gen_z = gen_z\n",
        "\n",
        "  # l1 is mean absolute error\n",
        "  def compile(self, mse, l1, disc_opt_z, disc_opt_h, gen_opt_z, gen_opt_h):\n",
        "    super().compile()\n",
        "    self.mse = mse\n",
        "    self.l1 = l1\n",
        "    self.disc_opt_z = disc_opt_z\n",
        "    self.disc_opt_h = disc_opt_h\n",
        "    self.gen_opt_z = gen_opt_z\n",
        "    self.gen_opt_h = gen_opt_h\n",
        "\n",
        "\n",
        "  def train_step(self, batch):\n",
        "    real_horse, real_zebra = batch\n",
        "\n",
        "    # training horse discriminator\n",
        "    with tf.GradientTape() as d_tape:\n",
        "\n",
        "      fake_horse = self.gen_h(real_zebra)\n",
        "\n",
        "      real_pred = self.disc_h(real_horse)\n",
        "      fake_pred = self.disc_h(fake_horse)\n",
        "      actual_true_pred = tf.zeros(tf.shape(real_pred))\n",
        "      actual_fake_pred = tf.ones(tf.shape(fake_pred))\n",
        "\n",
        "      h_loss_true = self.mse(actual_true_pred, real_pred)\n",
        "      h_loss_fake = self.mse(actual_fake_pred, fake_pred)\n",
        "\n",
        "      h_total_loss = (h_loss_true + h_loss_fake)/2\n",
        "\n",
        "    d_gradient = d_tape.gradient(h_total_loss, self.disc_h.trainable_variables)\n",
        "    self.disc_opt_h.apply_gradients(zip(d_gradient, self.disc_h.trainable_variables))\n",
        "\n",
        "\n",
        "    # training zebra discriminator\n",
        "    with tf.GradientTape() as d_tape:\n",
        "\n",
        "      fake_zebra = self.gen_z(real_horse)\n",
        "      fake_pred = self.disc_z(fake_zebra)\n",
        "      real_pred = self.disc_z(real_zebra)\n",
        "\n",
        "      actual_true_pred = tf.zeros(tf.shape(real_pred))\n",
        "      actual_fake_pred = tf.ones(tf.shape(fake_pred))\n",
        "\n",
        "      z_loss_true = self.mse(actual_true_pred, real_pred)\n",
        "      z_loss_fake = self.mse(actual_fake_pred, fake_pred)\n",
        "\n",
        "      z_total_loss = (z_loss_true + z_loss_fake)/2\n",
        "\n",
        "    d_gradient = d_tape.gradient(z_total_loss, self.disc_z.trainable_variables)\n",
        "    self.disc_opt_z.apply_gradients(zip(d_gradient, self.disc_z.trainable_variables))\n",
        "\n",
        "\n",
        "    # training the horse generator\n",
        "    with tf.GradientTape() as g_tape:\n",
        "      fake_horse = self.gen_h(real_zebra)\n",
        "\n",
        "      fake_pred = self.disc_h(fake_horse)\n",
        "      true_pred = tf.zeros(tf.shape(fake_pred))\n",
        "\n",
        "      mse_loss = self.mse(true_pred, fake_pred)\n",
        "\n",
        "      # cyclic loss\n",
        "      generated_real_zebra = self.gen_z(fake_horse)\n",
        "      cyclic_l1_loss = self.l1(real_zebra, generated_real_zebra)\n",
        "\n",
        "      # identity loss\n",
        "      # same_horse = self.gen_h(real_horse)\n",
        "      # identity_loss = self.l1(real_horse, same_horse)\n",
        "\n",
        "      # 10 is the lambda constant\n",
        "      # not using identity loss here it only increases accuracy on some specific problems\n",
        "      total_h_loss = (mse_loss + 10*cyclic_l1_loss)\n",
        "\n",
        "    h_gradient = g_tape.gradient(total_h_loss, self.gen_h.trainable_variables)\n",
        "    self.gen_opt_h.apply_gradients(zip(h_gradient, self.gen_h.trainable_variables))\n",
        "\n",
        "    # train the zebra generator\n",
        "    with tf.GradientTape() as g_tape:\n",
        "      fake_zebra = self.gen_z(real_horse)\n",
        "      fake_pred = self.disc_z(fake_zebra)\n",
        "      true_pred = tf.zeros(tf.shape(fake_pred))\n",
        "\n",
        "      mse_loss = self.mse(true_pred, fake_pred)\n",
        "\n",
        "      # cyclic loss for zebra\n",
        "      generated_horse = self.gen_h(fake_zebra)\n",
        "      cyclic_loss = self.l1(real_horse, generated_horse)\n",
        "\n",
        "      # identity loss\n",
        "      # same_zebra = self.gen_z(real_zebra)\n",
        "      # identity_loss = self.l1(real_zebra, same_zebra)\n",
        "\n",
        "      total_loss = (mse_loss + 10*cyclic_loss)\n",
        "\n",
        "    z_gradient = g_tape.gradient(total_loss, self.gen_z.trainable_variables)\n",
        "    self.gen_opt_z.apply_gradients(zip(z_gradient, self.gen_z.trainable_variables))\n",
        "\n",
        "    return {'d_loss_z':z_total_loss,'d_loss_h':h_total_loss, 'g_loss_z':total_loss, 'g_loss_h':total_h_loss}"
      ],
      "metadata": {
        "id": "RD5WJmSVBUDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "QiUO_txiqemc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "!gdown --id 18aOUuJVV6kIgpnqKoP-AW3cY6ZxhP9Aa\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download balraj98/horse2zebra-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GiMnzRujYQV",
        "outputId": "4a35ad46-27e5-4e8a-d431-e4b8d12f2015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18aOUuJVV6kIgpnqKoP-AW3cY6ZxhP9Aa\n",
            "To: /content/kaggle.json\n",
            "100% 68.0/68.0 [00:00<00:00, 460kB/s]\n",
            "Downloading horse2zebra-dataset.zip to /content\n",
            " 99% 110M/111M [00:06<00:00, 19.6MB/s]\n",
            "100% 111M/111M [00:06<00:00, 16.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/horse2zebra-dataset.zip')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "DA-RNZ8UqlrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainA = '/content/trainA' #a -> horses\n",
        "trainB = '/content/trainB' #b -> zebras"
      ],
      "metadata": {
        "id": "ALZ5Ut3HqyVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(trainA)),len(os.listdir(trainB))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "547Qh2BCrCA_",
        "outputId": "7b4404d3-cdb2-4384-9448-3610b465ffc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1067, 1334)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "horse_dataset = tf.keras.preprocessing.image_dataset_from_directory(trainA,\n",
        "                                                                    image_size=(256, 256),\n",
        "                                                                    label_mode=None,\n",
        "                                                                    batch_size=1)\n",
        "\n",
        "zebra_dataset = tf.keras.preprocessing.image_dataset_from_directory(trainB,\n",
        "                                                                     image_size=(256,256),\n",
        "                                                                     label_mode=None,\n",
        "                                                                     batch_size=1)"
      ],
      "metadata": {
        "id": "yvpA8C7qrad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10a90dc-3477-4af2-ef80-8c84013936b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1067 files belonging to 1 classes.\n",
            "Found 1334 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_dataset = tf.data.Dataset.zip((horse_dataset, zebra_dataset))"
      ],
      "metadata": {
        "id": "6k5dihRvSGRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_dataset.cardinality().numpy()*32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3ZES2N-Sb4M",
        "outputId": "094a572c-a990-4829-b3d6-fb52d5f98833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34144"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rescale(horse, zebra):\n",
        "  return (horse-127.5)/127.5, (zebra-127.5)/127.5"
      ],
      "metadata": {
        "id": "S0cFhECsUQ2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_dataset = combined_dataset.map(rescale, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "p6eHqzZFSeWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disc_h = Discriminator()\n",
        "disc_z = Discriminator()\n",
        "gen_h = Generator(9)\n",
        "gen_z = Generator(9)"
      ],
      "metadata": {
        "id": "BmMVRGv7S0N3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cgan = CycleGan(disc_h, disc_z, gen_h, gen_z)"
      ],
      "metadata": {
        "id": "LGfNDrl2VOo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cgan.compile(mse, l1, disc_opt_z, disc_opt_h, gen_opt_z, gen_opt_h)"
      ],
      "metadata": {
        "id": "xtK-ywjrVTy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cgan.fit(combined_dataset, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcRAODm-VX-w",
        "outputId": "ed43e88b-9cbd-4cdd-e7dd-dbf28153a1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1067/1067 [==============================] - 509s 422ms/step - d_loss_z: 0.2484 - d_loss_h: 0.2443 - g_loss_z: 4.2337 - g_loss_h: 4.8138\n",
            "Epoch 2/10\n",
            "1067/1067 [==============================] - 448s 420ms/step - d_loss_z: 0.2343 - d_loss_h: 0.2383 - g_loss_z: 4.1876 - g_loss_h: 4.6393\n",
            "Epoch 3/10\n",
            "1067/1067 [==============================] - 449s 421ms/step - d_loss_z: 0.2295 - d_loss_h: 0.2352 - g_loss_z: 4.2066 - g_loss_h: 4.5251\n",
            "Epoch 4/10\n",
            "1067/1067 [==============================] - 447s 419ms/step - d_loss_z: 0.2269 - d_loss_h: 0.2313 - g_loss_z: 4.1176 - g_loss_h: 4.5567\n",
            "Epoch 5/10\n",
            "1067/1067 [==============================] - 447s 419ms/step - d_loss_z: 0.2257 - d_loss_h: 0.2285 - g_loss_z: 4.0208 - g_loss_h: 4.5804\n",
            "Epoch 6/10\n",
            "1067/1067 [==============================] - 447s 419ms/step - d_loss_z: 0.2242 - d_loss_h: 0.2262 - g_loss_z: 3.9999 - g_loss_h: 4.5545\n",
            "Epoch 7/10\n",
            "1067/1067 [==============================] - 450s 422ms/step - d_loss_z: 0.2232 - d_loss_h: 0.2249 - g_loss_z: 3.9686 - g_loss_h: 4.5465\n",
            "Epoch 8/10\n",
            "1067/1067 [==============================] - 446s 418ms/step - d_loss_z: 0.2220 - d_loss_h: 0.2234 - g_loss_z: 3.9588 - g_loss_h: 4.5626\n",
            "Epoch 9/10\n",
            "1067/1067 [==============================] - 448s 420ms/step - d_loss_z: 0.2217 - d_loss_h: 0.2219 - g_loss_z: 3.9048 - g_loss_h: 4.5763\n",
            "Epoch 10/10\n",
            "1067/1067 [==============================] - 447s 419ms/step - d_loss_z: 0.2209 - d_loss_h: 0.2210 - g_loss_z: 3.8668 - g_loss_h: 4.5524\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7c66d6f13880>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "85PUa0tForyn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}